---
layout:     post
title:      "浅谈Java内存模型"
subtitle:   "虽然JSR-133在2004年就给出了Java内存模型和线程规范，但是我在这里依然还是要写这个内容，其目的为了加深自己在这块的理解，另外就是让公司团队也强化一下在多线程上面的造化。"
date:       2016-08-20 16:17:00
author:     "ryan"
header-img: "img/post-bg-06.jpg"
---


# 前序
我们还是稍微增加一些门槛，怎么使用java多闲的类和关键字，以及每个关键字的含义，这里就不多做讲解，必定这个属于java基础，本章的内容都是界定大家都已经熟悉java并发编程基础展开的讲解。废话不多说直接上代码：

```java
public class VolatileExample {
	 int x = 0;
	 int y = 0;
	 int a = 0;
	 int b = 0;
	
	
	public void go() throws Exception {
	    Thread one = new Thread(new Runnable() {
	        public void run() {
	            a = 1;
	            x = b;
	        }
	    });

	    Thread other = new Thread(new Runnable() {
	        public void run() {
	            b = 1;
	            y = a;
	        }
	    });
	    one.start();other.start();
	    one.join();other.join();
    	if (x == 0 && y == 0) {
    		System.out.println("(" + x + "," + y + ")");
    	} else if (x == 1 && y == 1) {
    		System.out.println("(" + x + "," + y + ")");
    	}
	}
}
```

执行go方法，在one thread和other thread跑完后(该机器处理器型号Intel(R) Xeon(R) CPU E5-2430，为什么要说明处理，后面的内容会说，我们会得到(0,1), (1,0), (0,0)这三个结果，这里我们就产生几个疑问了：

1.为什么没有(1,1)的结果？

2.安程序的之心顺序应该是(0,1)才会，为什么又多出来(1,0)，(0,0);

带着这些疑问我们开始讲解我们今天的内容



# Java线程调度

线程调度是为线程分配处理器的使用权限的过程，主要的调用方式有两种：一种是协同式线程调度和抢占式线程调度。

### 协同式线程调度

线程执行时间由自己来控制，它执行完后才会通知系统，让系统去调用下一个线程，因为不会在该线程中途将CPU的使用权切换的其他线程上面，而是等它执行完才通知系统切换另外一个，所以就不会存在多线程的同步问题，因为它本来就是同步的。该方式唯一的好处就是实现简单，无同步问题，但是坏处也非常突出，如果一个线程出了问题一直占用不通知系统，那么后续的线程会一直阻塞；以前windows 3.x系统使用的调度模式，导致系统极度不稳定，一个程序进程出了问题，会导致整个系统crash down。

### 抢占式线程调度

每个线程有系统来控制，就不会出现协同式线程调度的一个出问题导致所有阻塞的问题， Java虚拟机就是用该模式来调度线程，当然缺点就是同步问题了，这个问题就是我们今天要说的JMM需要解决的。抢占式线程调度从名字来看已经知道，分配给每个线程的使用CPU的时间是不定的，谁抢到谁先用，而且也不是一下用到线程结束，中间还可以被其他线程抢走，当然Java Thread提供的线程的优先级来设置，setPriority方法一共有三个值MIN, NORMAL, MAX，默认是NORMAL，当然MAX获取CPU的资源会相对更多了。

### 分析前序DEMO

回到之前前序的列子，有时候出现(1,0)，有时候出现(0,1)，我们就知道为什么了，我们肉眼看见one比other先调用start，由于Java虚拟机是抢占式线程调度，所以如果在那一瞬间one先开始，other后开始，但是由于系统CPU资源可能正在执行其他程序指令时，在等待系统调度时都有同等的机会，other thread是有可能抢在one直线开始执行的，所以会有(1,0)的情况，反之one先抢到那么就会是(0,1)的结果；抢占式线程调度，我刚才也说当一个线程执行的指令比较多的时候，也不会等你所有指令执行完了才切换到其他线程，可能中途系统就切换到其他线程，这样交替执行，所以也可能出现(1,1)，但是为什么我们演示没有出现呢，我判断的是因为我们目前的处理都是多核而且高频率，所以对于短的指令很可能在每次切换前就执行完了，下面代码可以印证(1,1)出现的可能性，而且也印证每次交替之前执行指令之多

```java
public class VolatileExampleForeach {
	public void go() throws Exception {
	    Thread one = new Thread(new Runnable() {
	        public void run() {
	            for(int i = 0; i < 10000; i++) {
	            	System.out.println(Thread.currentThread().getName());
	            }
	        }
	    });
	    
	    Thread other = new Thread(new Runnable() {
	        public void run() {
	        	for(int i = 0; i < 10000; i++) {
	            	System.out.println(Thread.currentThread().getName());
	            }
	        }
	    });
	    one.start();other.start();
	    one.join();other.join();
	}
}
```

打印结果出现是交替的，但是交替期很长，到这里我们理解为什么会出现(1,0),(0,1)，以及为们该出现的(1,1)没有出现，还剩下(0,0)这个奇葩的值，这个值出现是有重排序或者可见性导致的，需要下面的知识点来解释了；

# 重排序

重排序是指不同类型的CPU为了让其性能达到最大的一种优化措施，处理器里面有很多级流水线，越现在的处理级数越高，每级都并行负责处理从寄存器传递过来的指令，有些指令处理时间长，有些指令处理时间短，为了让每级都能饱和工作，处理器加入了乱序处理模块，也就是将后续指令会提前到一些时间长的质量之前执行掉，这就产生了重排序(Intel从Pentium Pro这块处理开始引入乱序处理)。

### as-if-serial

就算重排序，所有类型的处理器也会as-if-serial的语义来重排序，as-if-serial的语义是如果在单线程中前后执行的指令之间有依赖关系，是不会重排序的，当然这个强调是单线程，在多线程是之间存在依赖关系肯定是感知不了，所以我这里强调在单线程里面，再换句话说有第一条指令依赖第二条，如果到序那执行结果必将不同，所以也可以这样定义as-if-serial的语义是不影响结果的重排序，为了更加说明这点，我举了如下例子：

```java
1 int a = 1;
2 int b = 2
3 int c = a + b;
```

1和2之间是允许被重排序的，但是1和3，2和3是不允许的，因为他们之间有结果的依赖关系；

### 排序类型

有4种类型的重排序：load-store, load-load, store-load, store-store，不同类型的操作系统对他们支持度是不同的，支持度越高，那么这个处理的性能最大化就越强，下面表格描述：

|            | load-load | load-store | store-store | store-load |
| ---------- | --------- | ---------- | ----------- | ---------- |
| x86/x86-64 | 不支持       | 不支持        | 不支持         | 支持         |
| IA64       | 支持        | 支持         | 支持          | 支持         |
| PowerPC    | 支持        | 支持         | 支持          | 支持         |

x86这项应该是我们最熟悉的体系架构，这个架构下的CPU占有大致99%以上市场份额(intel和amd厂商)，因为大部分的操作系统都是x86体系下的，IA64是intel的安腾架构体系，这个CPU也很少见，但是他的64位处理性能远远高于x86-64(也一般用在服务器上)，有了IA64的架构体系，为什么x86-64还是这么普及，其原因是x86体系比ia64早出来，占领了市场，x86-64是兼容了之前的x86的所以就这么普及了。另外一个PowerPC，最早这个处理器是IBM推出来的，最早用在了现在很出名的APPLE PC上面，但是后面APPLE PC转战到了intel的x86体系下面直到今天，另外PowerPC的架构体系，被google收购的摩托罗拉之前的大部分芯片也是用了这个架构体系，现在PowerPC体系下的CPU也只有在服务器上面使用了。说了真么多，我们还没有分别解释这4种排序的意思：

#### load-load:

读1指令能和读2以及读2之后的读指令进行排序；

#### load-store:

读1指令能和写2以及写2之后的写指令进行排序；

#### store-store:

写1指令能和写2以及写2之后的写指令进行排序；

#### store-load:

写1指令能和读2以及读2之后的读指令进行排序；



### 分析前序DEMO

我们还剩下一个(0,0)的结果没有解释，有了上面的知识，我想这个结果也就有些理所当然了，看下面的分析；

one thread:

> set a=1, get b, set x=b;

other thread:

> set b=1, get a, set y=a;

因为store-load这种类型，x86体系是支持的，xeon处理器属于x86体系的，所以有可能出现下面的执行顺序；

| 线程           | 时段1      | 时段2      | 时段3     | 时段4        |
| ------------ | -------- | -------- | ------- | ---------- |
| one-thread   | get b(0) |          | set a=1 | set x=b(0) |
| other-thread |          | get a(0) | set b=1 | set y=a(0) |

上面这是将get b和get a排到所有指令之前执行，导致获取到的都是0，最后set x和y都是使用的是0值来设置，所以可以解释这种现象了，但是除了指令的重排序会导致外，还有一种可能也会导致，那就是内存模型中的可见性，后面的内容我们将说说为们可见性也会导致(0,0)的出现。

# 可见性

先来看一张图大致了解一下CPU是如何操纵内存数据的

 ![20160828_jmm_thread_visibility](https://ryanwli.github.io/img/2016/20160828_jmm_thread_visibility.png)

现在的CPU都是多核，以及都有自己高速缓存器，从存储设备的速度来排序大致是这样，CPU Cache > Memory > SSD > HDD，最早期的CPU是直接从Main Memory操纵数据，太慢了，后来设计了处理的高速缓存来代替直接从Main Memory操纵数据，从而让处理性能有指数倍的进步。但是这种速度提升了但是带来了不同处理线程之间对于共享数据的延迟性，如上图所示我可能在第一个CPU的Cache做了修改，但是在第二个CPU的Cache中还是以前老的值，所以当线程1还没有拿到在线程2里面修改的b=1的值时，以及将其值赋值给x，x就为0了，同理y也有可能会被设置为0，所以除了重排序会导致序言中的DEMO变成(0,0)外，多线程的可见性也会导致这个值。



# Memory Barriers

知道了可见性以及重排序是什么，那么我们就会问题如何解决重排序以及可见性的问题，在各个厂商的CPU都提供一个叫Memory Barriers(有的地方也叫Memory Fence)，中文就是内存屏障，他是用来告知CPU那些地方不需要重排序，那些地方需要立即可见，下面我就来说说这几种内存屏障。

#### load-load barriers(读读屏障)

禁止读2以及读2后面读指令和读1重排序；

#### store-store barriers(写写屏障)

1. 是确保写1的结果数据能立即被其他线程读到(会做一次Cache到Main Memory的写入操作，并使其他线程Cache对应共享数据过期);
2. 禁止写2以及写2后面的写指令和写1重排序；

#### load-store barriers(读写屏障)

1. 是确保写2的结果数据能立即被其他线程读到(会做一次Cache到Main Memory的写入操作，并使其他线程Cache对应共享数据过期);
2. 禁止写2以及写后的写指令和读1重排序；

#### store-load barriers(全能屏障)

1. 是确保写1之前的所有写指令的结果立即被其他线程读到(会做一次Full Cache到Main Memory的写操作，并使其他线程Cache对应共享数据过期)；
2. 禁止写1之后的所有指令重排序在写1以及写1之前的指令

细心一点儿可以看见和上面重排序的类型是对应的，Java内存模型在JIT编译时会根据不同的处理器架构来插入不同的屏障，来确保是按照程序员想要的顺序来的（前提是你加了同步关键字，下面章节会讲到，同步关键字和这些屏障的关系）；



# Happens-before





# volatile





# synchronized





# reetrantlock







# final





# 总结

