---
layout:     post
title:      "Spark Inside(Cluster)"
subtitle:   "(集群篇)Spark inside让普通开发人员可以通过该篇文档的学习可以快速上手Spark"
date:       2017-04-05 12:30:00
author:     "ryan"
header-img: "img/post-bg-02.jpg"
---

# Digest

前一篇主要讲单机模式下的Spark开发基础，这一篇文章主要分享一下Spark在集群里面的运行架构，以及如何使用Standalone方式来使用Spark的集群管理。



# 1. 集群运行时架构

在Spark集群中，有一个节点来协调其他节点的操作，该节点为“驱动器节点”，而其他节点就是“执行器节点”，从名字大概可以了解他们的作用了，先来看一下架构图：

![2017-04-17-spark-runtime-arch](/Users/ryan/Documents/git/ryanwli.github.io/img/2017/2017-04-17-spark-runtime-arch.png)

之前第一篇写的独立驱动程序就是在Spark驱动器节点执行，分析出需要多少任务，然后分发给其他执行器节点进行执行。他们之间的协作需要有一个集群管理器来做，Spark内部提供Standalone进群管理器，也可以使用如Hadoop Yarn，以及Apache Mesos来做管理都可以；



# 2. 驱动器与执行器节点

## 2.1 驱动器节点

在前一篇文章中，写的所有Java示例代码都是由spark-submit将这些代码提交到驱动器节点，驱动器节点执行main方法；然后在该进程中主要做两件事情“分析程序并生成任务”和“调度协作其他执行器节点”。

### 2.1.1 分析生成任务

我们再来看看上篇那张图：

![2017-04-13-spark-hdfs-partition](/Users/ryan/Documents/git/ryanwli.github.io/img/2017/2017-04-13-spark-hdfs-partition.png)

这张是Spark读取Hdfs文件，进行并行处理的过来；task是spark的最小执行单元，驱动器节点，负责分析提交的程序，并产生若干task；一个task可能是一个RDD操作，也可能是多个RDD操作的合并(spark驱动器进行会进行优化合并，加快执行效率)；最后讲这些任务打包发送到集群里面，分给这些执行器节点进行执行生成RDD分区；这一过程是将我们写的程序逻辑处理流程(这个逻辑处理流程官方术语也叫DAG, Directed Acyclic Graph)转换为物理执行计划的过程；

### 2.1.2 调度执行器节点

执行器节点启动后会向驱动器节点注册自己。这样驱动器节点就可以根据物理执行计划进行各执行器进程间的调度了；执行器节点负责实际计算，并能缓存中间计算结果，有了中间缓存结果，这样驱动器节点就之后后续task应该往哪些之前的执行器节点扔任务。每个执行器节点有多个线程，每个线程负责任务的执行，然后会将执行结果返回给驱动器节点进程；



## 2.2 执行器节点

执行器节点主要也负责两件事情：

第一，它负责执行由驱动器拆出来的task，并将task的执行结果返回给驱动程序；

第二，它还负责提供集群执行的中间缓存(可配，内存还是硬盘，默认内存)，在驱动器程序协调下可以将前后有依赖的task分配给同一个执行器节点，这样可以充分利用之前的中间缓存结果；



# 3. standalone集群模式

## 3.1 配置集群

## 3.2 提交应用

## 3.3 配置资源用量