---
layout:     post
title:      "Spark Inside(ALS推荐算法)"
subtitle:   "(ALS推荐算法应用)Spark inside让普通开发人员可以通过该篇文档的学习可以快速上手Spark"
date:       2017-04-17 12:30:00
author:     "ryan"
header-img: "img/post-bg-01.jpg"
---

# Digest

该篇文章以极其简单的语言来描述ALS推荐算法，以及如何基于Spark实现一个基于ALS推荐算法的分布式处理程序。



# 1. ALS算法推荐

互联网基本都是围绕人在产生信息，比如电商网用户购买产品，电影网用户看电影，音乐网用户听歌等等。但是由于对于歌，电影，商品，用户可能一辈子都买不完，看不完， 听不完这些东西。绝大部分用户，都只对其中的电影，歌，商品产生了关系，我们就要利用现有的这些关系来预测出没有和这些用户发生关系的哪些最有可能发生关系。这种关系在ALS算法里面，采用一个整数表示，比如豆瓣电影的用户对已经看过电影的评分；再比如网易云音乐对歌的收藏/切歌/循环听，这些用户行为动作产生的综合得分；再比如电商购买过，评价过，浏览过的产品，这些用户行为动作产证的综合得分。这些就会产生如下的一个稀疏矩阵：

|      | Item1 | Item2 | Item3 | Item4 |
| ---- | ----- | ----- | ----- | ----- |
| 用户1  | 5     |       | 1     |       |
| 用户2  |       | 2     |       |       |
| 用户3  |       |       | 3     | 4     |

ALS算法会将这个[用户xItem]的矩阵拆分为[用户xK]和[KxItem]两矩阵的乘积，这个K值就是ALS算法的核心，ALS算法要计算出这两个拆分后矩阵中的所有K值。

用户xK

|      | k1   | k2   | k3   | k4   | k5   |
| ---- | ---- | ---- | ---- | ---- | ---- |
| 用户1  | 2    | 1    | 2    | 1    | 1    |
| 用户2  | 1    | 0.5  | 3    | 0.3  | 2    |
| 用户3  | 4    | 3    | 1    | 4    | 2    |

KxItem

|      | Item1 | Item2 | Item3 | Item4 |
| ---- | ----- | ----- | ----- | ----- |
| k1   | 0.5   | 1     | 0.1   | 0.5   |
| k2   | 2     | 0.1   | 0.5   | 0.1   |
| k3   | 0.5   | 0.2   | 0.1   | 0.1   |
| k4   | 0.5   | 0.8   | 0.1   | 0.2   |
| k5   | 0.5   | 0.05  | 0.1   | 0.1   |

通过ALS算法拆分成这两个后，再两这两个拆分矩阵进行相乘，得到的结果和以前[用户xItem]已有的关系值，进行求误差值的方差求和，看看和远来已有用户和Item差多远。

ALS拆分后，再进行相乘得到的预测值：

|      | Item1           | Item2           | Item3 | Item3 |
| ---- | --------------- | --------------- | ----- | ----- |
| 用户1  | 5               | **<u>3.35</u>** | 1.1   | 1.6   |
| 用户2  | **<u>5.5</u>**  | 1.99            | 0.88  | 1.11  |
| 用户3  | **<u>11.5</u>** | 7.8             | 2.6   | 3.2   |

预测与实际

|           | 预测   | 实际   |
| --------- | ---- | ---- |
| 用户1-Item1 | 5    | 5    |
| 用户1-Item3 | 1.1  | 1    |
| 用户2-Item2 | 1.99 | 2    |
| 用户3-Item3 | 2.6  | 3    |
| 用户3-Item4 | 3.2  | 4    |

误差值的方差求和＝|(5-5)^2+(1.1-1)^2+(1.99-2)^2+(2.6-3)^2+(3.2-4)^2|=0.01-0.0001-0.16-0.64=0.7901;

上面的拆分，预测与实际方差求和计算，会迭代多次(Spark ALS算法实现默认是10次)，最后选一个方差最小的作为预测结果；上面加粗和下划线就是用户1-3最应该推荐给他们的Item;

中间ALS的拆分具体算法实现，能力有限，这里就不解释了，但是我给一些链接，感兴趣可以自行去了解：

https://zhihu.com/question/37031188/answer/111336809



# 2. 基于Spark ALS函数实现推荐

